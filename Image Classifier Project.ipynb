{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Bernd Schomburg (bbschomburg@gmail.com)\n",
    "Licence: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classifier for flower recognition\n",
    "\n",
    "\n",
    "In this project, an image classifier will be trained to recognize different species of flowers. For this purpose, [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, json, copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation and testing\n",
    "# Adapted from PyTorch's tutorial on transfer learning\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "std_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        std_transform\n",
    "    ]),\n",
    "    'valid': std_transform,\n",
    "    'test': std_transform\n",
    "}\n",
    "\n",
    "shuffle ={\n",
    "    'train': True,\n",
    "    'valid': False,\n",
    "    'test': False\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid','test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle= shuffle[x])\n",
    "              for x in ['train', 'valid','test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid','test']}\n",
    "\n",
    "num_labels = len(image_datasets['train'].classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping: load a mapping from category labels to category names\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Load a pretrained models from `torchvision.models` to get the image features and build a new feed-forward classifier using those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"resnet18\"\n",
    "\n",
    "if arch == \"resnet18\":\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "elif arch == \"densenet121\":\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    num_ftrs = model.classifier.in_features\n",
    "else:\n",
    "    raise ValueError('Network architecture not supported', arch)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "\n",
    "hidden_units = 1024\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(num_ftrs, hidden_units)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('d_out', nn.Dropout(p=0.5)),\n",
    "                          ('fc2', nn.Linear(hidden_units, num_labels)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "if arch == \"resnet18\":\n",
    "    model.fc = classifier\n",
    "elif arch == \"densenet\":\n",
    "    model.classifier = classifier\n",
    "\n",
    "model.class_to_idx = image_datasets['train'].class_to_idx      \n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic training routine\n",
    "Source: PyTorch's tutorial on transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterion, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "# Alternatively, one could remove the output layer, take criterion = nn.CrossEntropyLoss() and use LogSoftmax for prediction.\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Only parameters of the classifier layers are being optimized\n",
    "\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "model = train_model(model, criterion, optimizer,\n",
    "                         exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()   # Set model to evaluate mode\n",
    "    \n",
    "with torch.no_grad():\n",
    "# Iterate over data.\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "  \n",
    "   \n",
    "        outputs = model_conv(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "loss = running_loss /dataset_sizes['test']\n",
    "acc = running_corrects.double() / dataset_sizes['test']\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Testing complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "print('{} loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'Test', loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dict = {\n",
    "            'arch': arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'class_to_idx': model.class_to_idx,\n",
    "            'hidden_units': hidden_units,\n",
    "            'num_labels': num_labels,\n",
    "            'optimizer_dict': optimizer.state_dict(),\n",
    "            'learning_rate': optimizer.state_dict()['param_groups'][0]['lr'], \n",
    "             # = in_arg.lr * gamma**(num_epochs//step_size) \n",
    "            'epochs': num_epochs,\n",
    "            'batch_size': batch_size\n",
    "         }\n",
    "\n",
    "torch.save(checkpoint_dict, 'checkpoint_'+ arch+'_'+time.strftime(\"%Y%m%d\")+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    '''Loads a checkpoint and rebuilds the model\n",
    "    ''' \n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filepath)\n",
    "    else:\n",
    "    # Load GPU model on CPU\n",
    "        checkpoint = torch.load(filepath,\n",
    "                            map_location=lambda storage,\n",
    "                            loc: storage)      \n",
    "               \n",
    "    arch = checkpoint['arch']\n",
    "    \n",
    "    if arch == \"resnet18\":\n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "    elif arch == \"densenet121\":\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "    else:\n",
    "        raise ValueError('Network architecture not supported', arch)\n",
    "  \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "       \n",
    "    hidden_units = checkpoint['hidden_units']\n",
    "    num_labels = checkpoint['num_labels'] \n",
    "\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(num_ftrs, hidden_units)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('d_out', nn.Dropout(p=0.5)),\n",
    "                          ('fc2', nn.Linear(hidden_units, num_labels)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    if arch == \"resnet18\":\n",
    "        model.fc = classifier\n",
    "    elif arch == \"densenet\":\n",
    "        model.classifier = classifier\n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_dict']) #uncomment for further training, define optimizer before \n",
    "    # learning_rate = checkpoint['learning_rate'] #uncomment for further training \n",
    "    # start_epoch = checkpoint['epochs'] #uncomment for further training \n",
    "    # batch_size = checkpoint['batch_size'] #uncomment for further training \n",
    "\n",
    "    return model\n",
    "\n",
    "chp_file = 'respoint.pth'\n",
    "if os.path.isfile(chp_file):\n",
    "    print(\"Loading checkpoint '{}'\".format(chp_file))\n",
    "    model = load_checkpoint(chp_file)\n",
    "else:\n",
    "    print(\"No checkpoint found at '{}'\".format(chp_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "\n",
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns a Tensor\n",
    "    '''\n",
    "    pil_image = Image.open(image)\n",
    "    tensor_image = data_transforms['test'](pil_image).float()\n",
    "    \n",
    "    return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly chosen test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dir = random.choice(os.listdir(\"flowers/test\"))\n",
    "print(cat_to_name[rand_dir])\n",
    "image =  \"flowers/test/\" + rand_dir + \"/\" +random.choice(os.listdir(\"flowers/test/\"+rand_dir))\n",
    "imshow(process_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        img_tensor = process_image(image_path)\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        img_tensor.unsqueeze_(0) # resize the tensor (add dimension for batch)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "  \n",
    "    # apply data to model\n",
    "        output = model(img_tensor).topk(topk)\n",
    "        probs = torch.exp(output[0].to(\"cpu\")).numpy().tolist()[0]\n",
    "        classes = (output[1].to(\"cpu\")).numpy().tolist()[0]\n",
    "    \n",
    "    return probs, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image along with the top 5 classes\n",
    "\n",
    "probs, classes = predict(image, model, topk=5)\n",
    "\n",
    "idx_to_class = {v: k for k, v in image_datasets['train'].class_to_idx.items()}\n",
    "names =[]\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    names.append(cat_to_name[idx_to_class[classes[i]]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_tensor = process_image(image)\n",
    "    img_tensor = img_tensor.to(\"cpu\")\n",
    "    #img_tensor.unsqueeze_(0)\n",
    "\n",
    "img = img_tensor.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "# Undo preprocessing\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "    \n",
    "# Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "img = np.clip(img, 0, 1)    \n",
    "    \n",
    "y_pos = np.arange(len(classes))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(3,7.5), nrows=2)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title(names[0])\n",
    "ax1.axis('off')\n",
    "ax2.barh(y_pos, probs, align='center', color='blue')\n",
    "#ax2.set_aspect(1.0)\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(names, size='large');\n",
    "#ax2.set_title('Class Probability')\n",
    "#ax2.set_xlim(0, 1.1)\n",
    "ax2.axis('auto')\n",
    "ax2.invert_yaxis()\n",
    "_ = ax2.set_xlabel('Probabilities')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
